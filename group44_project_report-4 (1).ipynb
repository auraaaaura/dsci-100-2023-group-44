{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95d3751-951f-4ff1-8c14-e8e894ace7b0",
   "metadata": {},
   "source": [
    "# **Classifying coronary artery disease using age, blood pressure, blood cholesterol, and maximum heart rate.**\n",
    "## **Group Report**\n",
    "\n",
    "#### Zirun Xu, Aura Balita, and Sahil Babani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b11c6-69ca-4b11-bd45-152e6bbd54e5",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Coronary artery disease (CAD) is a cardiovascular condition caused by the accumulation of plaque in the coronary arteries, which are responsible for delivering blood to the heart. This plaque buildup gradually narrows the arteries, leading to reduced blood flow to the heart. CAD can lead to abnormal heart rhythms, heart attacks, and heart failure (Cleveland Clinic, n.d.). \n",
    "\n",
    "Four factors that increase the likelihood of heart disease are age, blood pressure, blood cholesterol levels and maximum heart rate. Individuals aged 65 and older are more likely to develop CAD due to the buildup of plaque over the years (National Institute on Aging, n.d.), while elevated blood pressure and high blood cholesterol levels are indicative of narrowed blood vessels due to plaque accumulation (Centers for Disease Control and Prevention, n.d.). Lastly, the max heart rate achieved during exercise testing is typically indicative of how well the heart is functioning. A high maximum heart rate usually means a healthier heart, while a lower one can signify a less healthy heart.).\n",
    "\n",
    "This project aims to determine whether it is possible to predict the likelihood of an individual having heart disease based on their age, blood pressure, blood cholesterol, and maximum heart rate and to determine which variable pairs would best give the best predictions, using the Cleveland database. These variables were selected because analyzing other variables would demand a more in-depth understanding of the subject.\n",
    "\n",
    "This database was constructed by gathering clinical test results from patients with chest pain symptoms at the Cleveland Clinic in Cleveland, Ohio database (Detrano, et al., 89)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e547a29-7a54-4d1b-97ae-a347731db0ef",
   "metadata": {},
   "source": [
    "### Loading the file and exploring the data\n",
    "The first step is to load the `tidyverse` and `tidymodels` packages that will be used for the analysis of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f4f4a5-6160-484a-838b-6e503a1dc54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a468baf-bfd0-4b2f-81ea-16e8bf456689",
   "metadata": {},
   "source": [
    "Our heart disease dataset is a `.csv` file with no headers. The `read_csv` function will be used to load the data, and headers will be added using the `colnames()` function. The headers come from the source. The data will then be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0115698e-faf2-4b83-a3a8-34540c30ff2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: 'processed.cleveland.data' does not exist in current working directory ('/home/jupyter/MICB 211').\n",
     "output_type": "error",
     "traceback": [
      "Error: 'processed.cleveland.data' does not exist in current working directory ('/home/jupyter/MICB 211').\nTraceback:\n",
      "1. read_csv(\"processed.cleveland.data\")",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
      "4. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     path <- enc2utf8(path)\n .     p <- split_path_ext(basename_utf8(path))\n .     if (write) {\n .         path <- normalizePath_utf8(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"processed.cleveland.data\")",
      "5. check_path(path)",
      "6. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n .     paste0(\" in current working directory ('\", getwd(), \"')\")\n . }, \".\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "# Loading and adding headers to the heart disease data\n",
    "heart_data <- read_csv(\"processed.cleveland.data\") \n",
    "colnames(heart_data) <- c(\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "                     \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\")\n",
    "head(heart_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0cba98-ea28-49e9-9abf-8ba73cd747f9",
   "metadata": {},
   "source": [
    "### Describing the variables in the heart disease data set\n",
    "\n",
    "Patients experiencing chest pain symptoms, also known as angina, often have a higher probability of being diagnosed with heart disease and are often recommended for coronary angiography. An angiogram involves using x-ray imaging to examine the blood vessels in a person's heart. Its purpose is to assess the condition of these vessels and the circulation of blood within them. At the Cleveland Clinic, 303 patients undergoing coronary angiography had 14 different variables measured.\n",
    "\n",
    "The information gathered included four clinical details: age, sex, type of chest pain, and systolic blood pressure. Other tests included drawing blood to measure cholesterol levels and blood sugar, electrocardiograms, in which the electrical activity of the heart is measured, thallium scans, in which a radioactive tracer is used to see how much blood is reaching different parts of your heart, and fluoroscopy for coronary calcium, which is a procedure used to look at calcium in the heart's blood vessels.\n",
    "\n",
    "These variables are described below:\n",
    "\n",
    "1. **age:** age in years\n",
    "2. **sex:** sex of the individual (1 = male; 0 = female)\n",
    "3. **cp:** chest pain type\n",
    "4. **trestbps:** resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. **chol:** serum cholesterol in mg/dl\n",
    "6. **fbs:** whether fasting blood sugar is greater than 120 mg/dl (1 = true; 0 = false)\n",
    "7. **restecg:** resting electrocardiographic results\n",
    "8. **thalach:** maximum heart rate achieved (in bpm)\n",
    "9. **exang:** exercise induced angina (1 = yes; 0 = no)\n",
    "10. **oldpeak:** ST depression induced by exercise relative to rest\n",
    "11. **slope:** the slope of the peak exercise ST segment\n",
    "12. **ca:** number of major vessels (0-3) colored by flourosopy\n",
    "13. **thal:** thalassemia\n",
    "14. **num:** diagnosis of heart disease (0 = not present; 1, 2, 3, 4 = present)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89872aa-a190-43c8-b855-d86bec380bbc",
   "metadata": {},
   "source": [
    "### Wrangling and cleaning the data\n",
    "When the database was inspected with the editor, it was found that there were missing values \"?\" in the table. Thus, the data was cleaned and wrangled into a tidy format by converting the missing data \"?\" into NA values, and then removing all missing values from the dataset using the `na.omit()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d0910-22bd-4e43-aef6-26acca620f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting \"?\" in cells into \"NA\"\n",
    "heart_data[heart_data == \"?\"] <- NA\n",
    "\n",
    "# Removing missing values\n",
    "heart_data <- na.omit(heart_data)\n",
    "head(heart_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f9768-85bc-4402-ad5f-feaf9a63f675",
   "metadata": {},
   "source": [
    "The variable **num** indicates the diagnosis of the heart disease, with 0 meaning heart disease is not present, and 1, 2, 3, and 4 meaning that heart disease is present. However, this is too confusing. Thus, we will use `mutate()`, `as.factor()`, and `case_when()` to make things more readable. For the case that num = 0, no heart disease occurs, and the disease observation will say \"No\". For the case that num = 1, 2, 3, 4, heart disease is present, and the disease observation will say \"Yes\". \n",
    "\n",
    "To make things more readable, the following variables will be renamed using `colnames()`:\n",
    "* **trestbps** to **rest_bp**\n",
    "* **thalach** to **max_heart**\n",
    "* **num** to **disease**.\n",
    "\n",
    "As mentioned in the introduction, we will only be using age, blood pressure, blood cholesterol, maximum heart rate, and the final diagnosis for our analysis. Thus, we will create a new tibble using these five variables using `select()`. The new tibble will be renamed `heart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca8071-6a89-476b-a490-b08da907c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting and renaming column names\n",
    "heart <- heart_data |>\n",
    "    select(age, trestbps, chol, thalach, num)\n",
    "\n",
    "colnames(heart) <- c(\"age\", \"rest_bp\", \"chol\", \"max_heart\", \"disease\")\n",
    "\n",
    "# Converting integer values to \"Yes\" or \"No\"\n",
    "heart <- heart |>\n",
    "    mutate(disease = as.factor(case_when(disease > 0 ~ \"Yes\", disease ==  0 ~ \"No\")))\n",
    "\n",
    "head(heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d612b59-ac6e-4ebe-888f-27e8417e58d1",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2487a-9907-46e1-917f-65bc517aed2f",
   "metadata": {},
   "source": [
    "### Summary of the data\n",
    "\n",
    "The next step is to perform a summary of the dataset using `group_by()`, `summarize()`, and `n()` to find the number and percentage of disease and no disease observations in our dataset. After, the percentage in each group is found by dividing the total number of observations and multiplying by 100.\n",
    "\n",
    "There are 137 (46%) disease observations and 159 (54%) no disease observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1007f20-bc4e-4fea-a9eb-ea24733f6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs <- nrow(heart)\n",
    "heart |>\n",
    "    group_by(disease) |>\n",
    "    summarize(\n",
    "        count = n(),\n",
    "        percentage = n() / num_obs *100\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde58548-75ba-4d37-9ba3-b24effab8026",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "Data splitting is an essential and critical step, involving the division of the dataset into two subsets: a training set and a testing set. Here the training set is accumulated of 75% of the original dataset and 25% of it is the testing set. \n",
    "\n",
    "The training set is used to teach the model by making them identify to the patterns within the data and helps by preventing overfitting, where a model may memorize the training data but fails to generalize to new instances. \n",
    "\n",
    "The testing set is used to gain insights into its ability to make accurate predictions on the unseen data, which simulates as a real-world scenario. Based on this performance, metrics like accuracy and precision is calculated. \n",
    "\n",
    "In this step, `initial_split()`, `training()`, and `testing()` are used.\n",
    "\n",
    "A seed is set to ensure reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53fabc-6353-446b-b2d9-40c22f7a2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into the training and testing sets\n",
    "set.seed(1234)\n",
    "\n",
    "heart_split <- initial_split(heart, prop = 0.75, strata = disease)  \n",
    "\n",
    "heart_train <- training(heart_split)   \n",
    "heart_test <- testing(heart_split)\n",
    "\n",
    "head(heart_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8a315-374e-447e-8274-fa9269e19e27",
   "metadata": {},
   "source": [
    "### Summary of data\n",
    "\n",
    "Below provides a summary statistic on the testing data, grouping the data by the presence or absense of heart disease. The functions `group_by()` and `summarize()` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21929b4b-8053-472c-b344-af2aee454d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_summary <- heart_train |>\n",
    "                 group_by(disease) |>\n",
    "                 summarize(observations = n(), \n",
    "                           mean_age = mean(age), \n",
    "                           mean_chol = mean(chol),\n",
    "                           mean_max_heart = mean(max_heart))\n",
    "heart_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eede38-bc88-4a1e-8674-1859b7c2d9c9",
   "metadata": {},
   "source": [
    "### Preliminary data visualization\n",
    "\n",
    "Below is the data visualization of the relationship between the Max Heart Rate and the Cholesterol Levels. \n",
    "This visualization provides an exploratory analysis, allowing for a visual assessment of potential patterns or trends between these two key health indicators and their association with heart disease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1709df-b06e-4934-a048-3ab7820bbad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'heart_train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'heart_train' not found\nTraceback:\n",
      "1. ggplot(heart_train, aes(x = max_heart, y = chol, color = disease))"
     ]
    }
   ],
   "source": [
    "max_heart_chol_plot <- heart_train |>\n",
    "    ggplot(aes(x = max_heart, y = chol, color = disease)) +\n",
    "    geom_point() +\n",
    "        labs(x = \"Max Heart Rate (in bpm)\",\n",
    "             y = \"Serum Cholesterol (in mg/dl)\",\n",
    "             color = \"Heart Disease\",\n",
    "            title = \"Max Heart Rate vs. Cholesterol Levels Graph\", subtitle = \"Based on disease and no disease observations\")\n",
    "max_heart_chol_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b1697-2e7a-41a1-a914-c1e9d419684e",
   "metadata": {},
   "source": [
    "### Determining the most suitable $k$ value\n",
    "\n",
    "This step is performing the k-Nearest Neighbors (k-NN) model tuning using cross-validation. This step is done to improve the performance of the model and prevent overfitting or underfitting. Cross-validation is also performed in order to indentify the outliers before applying the algorithm. \n",
    "The results are collected and filtered to focus on accuracy metrics for different numbers of neighbors. This analysis helps identify the optimal number of neighbors for the k-NN model, informing the final model configuration for heart disease classification. A seed is set to ensure reproducibility of results.\n",
    "First, a recipe is created with `recipe()`, and the data is scaled with `step_scale()` and `step_center()`. `nearest_neighbor()`, `vfold_cv()`, and `tibble()` are also used, and finally, a `workflow()` is created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d15ae4d-af8d-4943-bb80-73df63206402",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'heart_train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'heart_train' not found\nTraceback:\n",
      "1. step_center(step_scale(recipe(disease ~ age + rest_bp + chol + \n .     max_heart, data = heart_train), all_predictors()), all_predictors())",
      "2. add_step(recipe, step_center_new(terms = enquos(...), trained = trained, \n .     role = role, means = means, na_rm = na_rm, skip = skip, id = id, \n .     case_weights = NULL))",
      "3. step_scale(recipe(disease ~ age + rest_bp + chol + max_heart, \n .     data = heart_train), all_predictors())",
      "4. add_step(recipe, step_scale_new(terms = enquos(...), role = role, \n .     trained = trained, sds = sds, factor = factor, na_rm = na_rm, \n .     skip = skip, id = id, case_weights = NULL))",
      "5. recipe(disease ~ age + rest_bp + chol + max_heart, data = heart_train)",
      "6. recipe.formula(disease ~ age + rest_bp + chol + max_heart, data = heart_train)",
      "7. rlang::is_missing(data)"
     ]
    }
   ],
   "source": [
    "set.seed(1234) \n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "recipe <- recipe(disease ~ age + rest_bp + chol + max_heart, data = heart_train) |>\n",
    "   step_scale(all_predictors()) |>\n",
    "   step_center(all_predictors())\n",
    "\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"classification\")\n",
    "\n",
    "vfold <- vfold_cv(heart_train, v = 5, strata = disease)\n",
    "\n",
    "k_vals <- tibble(neighbors = seq(from = 2, to = 15, by = 1))\n",
    "\n",
    "cross_val_fit <- workflow() |>\n",
    "      add_recipe(recipe) |>\n",
    "      add_model(knn_tune) |>\n",
    "      tune_grid(resamples = vfold, grid = k_vals) |>\n",
    "      collect_metrics() |>\n",
    "      filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b93577-d342-463e-b337-ca0779346a6a",
   "metadata": {},
   "source": [
    "### Plotting $k$ vs Accuracy\n",
    "\n",
    "Below is a graphical visualization of the relationship between the number of neighbours chosen and the accuracy estimate. The plot provides critical insights into the impact of the number of neighbors on model performance, aiding in the selection of an optimal configuration for the k-NN algorithm.\n",
    "\n",
    "Moreover, it can be identified that the accuracy is peaked and optimal when the neighbours are 3 to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f18b56-5651-40c7-9a98-4a16832a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_plot <- ggplot(data = cross_val_fit, aes(x = neighbors, y = mean)) +\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\") + \n",
    "      theme(text = element_text(size = 12))\n",
    "\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ae7ee-afea-4e5d-b1ad-4ebb430b56c2",
   "metadata": {},
   "source": [
    "5-fold cross-validation helps us evaluate the accuracy of the classifier for each value of k by taking the average of the accuracies in each of the 5 resamples. k = 3 is finally chosen because it has the highest mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e76e3c-ae17-4460-baad-c3ffa981235d",
   "metadata": {},
   "source": [
    "### Creating a $k$-NN classification model\n",
    "\n",
    "By consolidating the learning process through model fitting, the model is able to predict outcomes based on the associations it has learnt from the training set of data. Now that the model has been trained, its performance on untested data can be assessed, offering valuable information about its prediction power. A seed is set to ensure reproducibility of results. The functions `nearest_neighbor()` and `workflow()` is used in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ebaed-61df-498b-8aae-83980d126e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "\n",
    "heart_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"classification\")\n",
    "\n",
    "heart_fit <- workflow() |>\n",
    "      add_recipe(recipe) |>\n",
    "      add_model(heart_spec) |>\n",
    "      fit(data = heart_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa2ac9-5841-4a68-a457-cb917651ba2e",
   "metadata": {},
   "source": [
    "### Testing the model against the testing data\n",
    "\n",
    "Firstly, the predictions are made on the testing set using `predict()`. The predictions are then bound to the original test data for further analysis. \n",
    "\n",
    "Further, to test the performance of the prediction, the code calculated the classification metrics including the accuracy and Cohen's Kappa, comparing predicted and true disease labels using the function `metrics()`. \n",
    "\n",
    "Lastly, a confusion matrix was generated using `conf_mat()`, providing a detailed breakdown of correct and incorrect predictions for heart disease and non-heart disease cases.\n",
    "\n",
    "The confusion matrix and these metrics are essential for assessing the model's efficacy, measuring its precision, and pinpointing particular areas of success and future development. They offer practical insights for improving the model's prediction power and refinement.  A seed is set to ensure reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf2b0d-3812-476a-9f03-726fc22ae026",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "\n",
    "heart_predictions <- predict(heart_fit, heart_test) |>\n",
    "      bind_cols(heart_test)\n",
    "\n",
    "heart_metrics <- heart_predictions |>\n",
    "      metrics(truth = disease, estimate = .pred_class)\n",
    "heart_metrics\n",
    "\n",
    "heart_conf_mat <- heart_predictions |> \n",
    "      conf_mat(truth = disease, estimate = .pred_class)\n",
    "heart_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdaf39a-de0f-4714-a40f-80495d374b31",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "In this analysis, we sought to classify the coronary artery disease based on the key indicators of health. With the use of k-Nearest-Neighbours (k-NN) algorithm, we conducted this comprehensive exploration, training and evaluation of the model. The first stage of our model made the dataset undergo through rigorous preprocess, including the handling of missing values and transforming them for clarity. For a better visualisation, a relationship between the maximum heart rate and cholesterol levels was displayed, categorised by the presence and absence of heart disease. \n",
    "The k-NN classification model was chosen and optimised through a grid search for the optimal number of neighbours using 5-fold-cross-validation. A plot was also drawn which displayed the algorithm reaching an optimal accuracy when there are 3 to 4 neighbours. On the test data, the k-NN model achieved an accuracy of approximately 58.67% and the Kappa statistic, measuring agreement beyond chance, was approximately 0.168, indicating moderate predictive performance.\n",
    "Further, the confusion matrix provided a detailed breakdown of model predictions, highlighting correct and incorrect classifications for heart disease and non-heart disease cases.\n",
    "Lastly, the model demonstrated a nuanced understanding of the relationship between health indicators and heart disease, capturing distinctions in average values for key features and the choice of the number of neighbours played a significant role in influencing the model accuracy, emphasising the importance of hyper parameter tuning.\n",
    "\n",
    "This is somewhat we were expected to find, however, due to a lower accuracy because of different factors, there is still room of improvement that could be done. Our expected outcome for an indivudual to have heart disease was expected to have have high levels of cholesterol, lower maximum heart rates and probably be older. Our results somewhat align with the expected outcomes in some aspects, but still there are nuances that need to be considered. Our model needs refinement and more in-depth exploration in order for it capture the complexities of heart disease with a higher precision. \n",
    "\n",
    "If this model is refined and brought up to mark where it is capable enough to recognize the complexities, it can have several potential impacts, both in the context of medical and data science as well. \n",
    "It can be used to develop extensive research insights into the relationship between specific health indicators and the likelihood of coronary artery disease. These insights may guide further medical research and contribute to a deeper understanding of cardiovascular health.\n",
    "Also, it is helpful for clinical decision support in the medical field, it could serve as a valuable tool for healthcare professionals in the early identification of individuals at risk of coronary artery disease. \n",
    "\n",
    "\n",
    "Some future questions that could be answered are as follows:\n",
    "1. How can we mitigate bias in heart disease classification algorithms to ensure equitable diagnosis and treatment for all patients.\n",
    "2. What is the long-term impact of using heart disease classification models. Will it eventually replace doctors?\n",
    "3. How accurate are disease classification models in general? How can they be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c3be5-48b5-4a3b-b1e7-3409be6c3734",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85388e-4f12-4eae-88cf-64e801930992",
   "metadata": {},
   "source": [
    "* [Cleveland Clinic. “Coronary Artery Disease.”](my.clevelandclinic.org/health/diseases/16898-coronary-artery-disease)\n",
    "* [“Coronary Artery Disease.” Centers for Disease Control and Prevention](www.cdc.gov/heartdisease/coronary_ad.htm#:~:text=To%20find%20out%20your%20risk,about%20heart%20disease%20risk%20factors.) \n",
    "* [Detrano, et al. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. The American journal of cardiology, 64 5, 304-10.](https://www.ajconline.org/article/0002-9149(89)90524-9/pdf)\n",
    "* [“Heart Health and Aging.” National Institute on Aging, U.S. Department of Health and Human Services](https://www.nia.nih.gov/health/heart-health/heart-health-and-aging#how)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
